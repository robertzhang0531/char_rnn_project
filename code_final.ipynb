{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char RNN From Scratch - Sherlock Holmes\n",
    "\n",
    "In this notebook, I'll build a character-wise RNN trained on Sherlock Holmes and generate new text based on the text from the book.\n",
    "\n",
    "References:<br />\n",
    "Andrej Karpathy's [post on RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)<br />\n",
    "[implementation in Torch](https://github.com/karpathy/char-rnn)<br />\n",
    "[here at r2rt](http://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html)<br />\n",
    "[Sherjil Ozair](https://github.com/sherjilozair/char-rnn-tensorflow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the text file and convert it into integers for our network to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cnus.txt', 'r') as f:\n",
    "    text=f.read()\n",
    "vocab = sorted(set(text))\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "encoded = np.array([vocab_to_int[c] for c in text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the first 500 characters / interger encodings to make sure everything is peachy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n                          THE COMPLETE SHERLOCK HOLMES\\n\\n                               Arthur Conan Doyle\\n\\n\\n\\n                                Table of contents\\n\\n               A Study In Scarlet\\n\\n               The Sign of the Four\\n\\n                  The Adventures of Sherlock Holmes\\n               A Scandal in Bohemia\\n               The Red-Headed League\\n               A Case of Identity\\n               The Boscombe Valley Mystery\\n               The Five Orange Pips\\n               The Man wit'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45, 33, 30,  1,\n",
       "       28, 40, 38, 41, 37, 30, 45, 30,  1, 44, 33, 30, 43, 37, 40, 28, 36,\n",
       "        1, 33, 40, 37, 38, 30, 44,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1, 26, 72, 74, 62, 75, 72,  1, 28, 69, 68, 55,\n",
       "       68,  1, 29, 69, 79, 66, 59,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1, 45, 55, 56, 66, 59,  1, 69, 60,\n",
       "        1, 57, 69, 68, 74, 59, 68, 74, 73,  0,  0,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1, 26,  1, 44, 74, 75, 58, 79,  1,\n",
       "       34, 68,  1, 44, 57, 55, 72, 66, 59, 74,  0,  0,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45, 62, 59,  1, 44, 63, 61,\n",
       "       68,  1, 69, 60,  1, 74, 62, 59,  1, 31, 69, 75, 72,  0,  0,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45,\n",
       "       62, 59,  1, 26, 58, 76, 59, 68, 74, 75, 72, 59, 73,  1, 69, 60,  1,\n",
       "       44, 62, 59, 72, 66, 69, 57, 65,  1, 33, 69, 66, 67, 59, 73,  0,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 26,  1, 44,\n",
       "       57, 55, 68, 58, 55, 66,  1, 63, 68,  1, 27, 69, 62, 59, 67, 63, 55,\n",
       "        0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45,\n",
       "       62, 59,  1, 43, 59, 58, 10, 33, 59, 55, 58, 59, 58,  1, 37, 59, 55,\n",
       "       61, 75, 59,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, 26,  1, 28, 55, 73, 59,  1, 69, 60,  1, 34, 58, 59, 68, 74,\n",
       "       63, 74, 79,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, 45, 62, 59,  1, 27, 69, 73, 57, 69, 67, 56, 59,  1, 47, 55,\n",
       "       66, 66, 59, 79,  1, 38, 79, 73, 74, 59, 72, 79,  0,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45, 62, 59,  1, 31, 63,\n",
       "       76, 59,  1, 40, 72, 55, 68, 61, 59,  1, 41, 63, 70, 73,  0,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 45, 62, 59,  1,\n",
       "       38, 55, 68,  1, 77, 63, 74], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the length of our vocabulary list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making mini-batches for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr, batch_size, n_steps):\n",
    "    '''Create a generator that returns batches of size\n",
    "       batch_size x n_steps from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       batch_size: Batch size, the number of sequences per batch\n",
    "       n_steps: Number of sequence steps per batch\n",
    "    '''\n",
    "    # Get the number of characters per batch and number of batches we can make\n",
    "    chars_per_batch = batch_size * n_steps\n",
    "    n_batches = len(arr)//chars_per_batch\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:n_batches * chars_per_batch]\n",
    "    \n",
    "    # Reshape into batch_size rows\n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        # The features\n",
    "        x = arr[:, n:n+n_steps]\n",
    "        # The targets, shifted by one\n",
    "        y_temp = arr[:, n+1:n+n_steps+1]\n",
    "        \n",
    "        y = np.zeros(x.shape, dtype=x.dtype)\n",
    "        y[:,:y_temp.shape[1]] = y_temp\n",
    "        \n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = get_batches(encoded, 10, 50)\n",
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[ 0  0  0  0  1  1  1  1  1  1]\n",
      " [ 1  1  1  1  1 56 66 69 69 58]\n",
      " [74  1 77 55 73  1 72 59 67 69]\n",
      " [44 74 72 59 59 74 11  3  0  0]\n",
      " [68  1 62 63 73  1 72 69 69 67]\n",
      " [ 1  1 60 69 66 66 69 77 59 58]\n",
      " [ 0  1  1  1  1  1 63 68 73 59]\n",
      " [ 1  1  1  1 66 69 69 65 59 58]\n",
      " [69 66 69 75 72 59 58  1 56 72]\n",
      " [55 72 58 66 79  1 59 68 69 75]]\n",
      "\n",
      "y\n",
      " [[ 0  0  0  1  1  1  1  1  1  1]\n",
      " [ 1  1  1  1 56 66 69 69 58  1]\n",
      " [ 1 77 55 73  1 72 59 67 69 76]\n",
      " [74 72 59 59 74 11  3  0  0  1]\n",
      " [ 1 62 63 73  1 72 69 69 67  1]\n",
      " [ 1 60 69 66 66 69 77 59 58  1]\n",
      " [ 1  1  1  1  1 63 68 73 59 72]\n",
      " [ 1  1  1 66 69 69 65 59 58  1]\n",
      " [66 69 75 72 59 58  1 56 72 63]\n",
      " [72 58 66 79  1 59 68 69 75 61]]\n"
     ]
    }
   ],
   "source": [
    "print('x\\n', x[:10, :10])\n",
    "print('\\ny\\n', y[:10, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "\n",
    "### Inputs\n",
    "\n",
    "Create our input placeholders for the training data and the targets. We'll also create a placeholder for dropout layers called `keep_prob`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inputs(batch_size, num_steps):\n",
    "    ''' Define placeholders for inputs, targets, and dropout \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size: Batch size, number of sequences per batch\n",
    "        num_steps: Number of sequence steps in a batch\n",
    "        \n",
    "    '''\n",
    "    # Declare placeholders we'll feed into the graph\n",
    "    inputs = tf.placeholder(tf.int32, [batch_size, num_steps], name='inputs')\n",
    "    targets = tf.placeholder(tf.int32, [batch_size, num_steps], name='targets')\n",
    "    \n",
    "    # Keep probability placeholder for drop out layers\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return inputs, targets, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Cell\n",
    "\n",
    "`build_lstm` function creates the LSTM cells we'll use in the hidden layer and the initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, num_layers, batch_size, keep_prob):\n",
    "    ''' Build LSTM cell.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        keep_prob: Scalar tensor (tf.placeholder) for the dropout keep probability\n",
    "        lstm_size: Size of the hidden layers in the LSTM cells\n",
    "        num_layers: Number of LSTM layers\n",
    "        batch_size: Batch size\n",
    "\n",
    "    '''\n",
    "    ### Build the LSTM Cell\n",
    "    \n",
    "    def build_cell(lstm_size, keep_prob):\n",
    "        # Use a basic LSTM cell\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        \n",
    "        # Add dropout to the cell\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return drop\n",
    "    \n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([build_cell(lstm_size, keep_prob) for _ in range(num_layers)])\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Output\n",
    "\n",
    "Create the output layer. Connect the output of the RNN cells to a full connected layer with a softmax output. The softmax output gives us a probability distribution we can use to predict the next character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_output(lstm_output, in_size, out_size):\n",
    "    ''' Build a softmax layer, return the softmax output and logits.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        x: Input tensor\n",
    "        in_size: Size of the input tensor, for example, size of the LSTM cells\n",
    "        out_size: Size of this softmax layer\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Reshape output so it's a bunch of rows, one row for each step for each sequence.\n",
    "    # That is, the shape should be batch_size*num_steps rows by lstm_size columns\n",
    "    seq_output = tf.concat(lstm_output, axis=1)\n",
    "    x = tf.reshape(seq_output, [-1, in_size])\n",
    "    \n",
    "    # Connect the RNN outputs to a softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        softmax_w = tf.Variable(tf.truncated_normal((in_size, out_size), stddev=0.1))\n",
    "        softmax_b = tf.Variable(tf.zeros(out_size))\n",
    "    \n",
    "    # Since output is a bunch of rows of RNN cell outputs, logits will be a bunch\n",
    "    # of rows of logit outputs, one for each step and sequence\n",
    "    logits = tf.matmul(x, softmax_w) + softmax_b\n",
    "    \n",
    "    # Use softmax to get the probabilities for predicted characters\n",
    "    out = tf.nn.softmax(logits, name='predictions')\n",
    "    \n",
    "    return out, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loss\n",
    "\n",
    "Use the logits and targets and calculate the softmax cross-entropy loss. First we need to one-hot encode the targets, then reshape the one-hot targets so it's a 2D tensor with size $(M*N) \\times C$ where $C$ is the number of classes/characters we have. Since the LSTM outputs are reshaped and run through a fully connected layer with $C$ units, the logits will also have size $(M*N) \\times C$.\n",
    "\n",
    "Then we run the logits and targets through `tf.nn.softmax_cross_entropy_with_logits` and find the mean to get the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loss(logits, targets, lstm_size, num_classes):\n",
    "    ''' Calculate the loss from the logits and the targets.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        logits: Logits from final fully connected layer\n",
    "        targets: Targets for supervised learning\n",
    "        lstm_size: Number of LSTM hidden units\n",
    "        num_classes: Number of classes in targets\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # One-hot encode targets and reshape to match logits, one row per batch_size per step\n",
    "    y_one_hot = tf.one_hot(targets, num_classes)\n",
    "    y_reshaped = tf.reshape(y_one_hot, logits.get_shape())\n",
    "    \n",
    "    # Softmax cross entropy loss\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "Build the optimizer to clip the gradients above some threshold to address issues like gradients exploding and disappearing. That is, if a gradient is larger than that threshold, we set it to the threshold. This will ensure the gradients never grow overly large. Then we use an AdamOptimizer for the learning step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, grad_clip):\n",
    "    ''' Build optmizer for training, using gradient clipping.\n",
    "    \n",
    "        Arguments:\n",
    "        loss: Network loss\n",
    "        learning_rate: Learning rate for optimizer\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put the network together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN:\n",
    "    \n",
    "    def __init__(self, num_classes, batch_size=64, num_steps=50, \n",
    "                       lstm_size=128, num_layers=2, learning_rate=0.001, \n",
    "                       grad_clip=5, sampling=False):\n",
    "    \n",
    "        if sampling == True:\n",
    "            batch_size, num_steps = 1, 1\n",
    "        else:\n",
    "            batch_size, num_steps = batch_size, num_steps\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Build the input placeholder tensors\n",
    "        self.inputs, self.targets, self.keep_prob = build_inputs(batch_size, num_steps)\n",
    "\n",
    "        # Build the LSTM cell\n",
    "        cell, self.initial_state = build_lstm(lstm_size, num_layers, batch_size, self.keep_prob)\n",
    "\n",
    "        ### Run the data through the RNN layers\n",
    "        # First, one-hot encode the input tokens\n",
    "        x_one_hot = tf.one_hot(self.inputs, num_classes)\n",
    "        \n",
    "        # Run each sequence step through the RNN and collect the outputs\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell, x_one_hot, initial_state=self.initial_state)\n",
    "        self.final_state = state\n",
    "        \n",
    "        # Get softmax predictions and logits\n",
    "        self.prediction, self.logits = build_output(outputs, lstm_size, num_classes)\n",
    "        \n",
    "        # Loss and optimizer (with gradient clipping)\n",
    "        self.loss = build_loss(self.logits, self.targets, lstm_size, num_classes)\n",
    "        self.optimizer = build_optimizer(self.loss, learning_rate, grad_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Hyperparameters we need to tune for the network. \n",
    "\n",
    "* `batch_size` - Number of sequences running through the network in one pass\n",
    "* `num_steps` - Number of characters in the sequence the network is trained on\n",
    "* `lstm_size` - The number of units in the hidden layers\n",
    "* `num_layers` - Number of hidden LSTM layers to use\n",
    "* `learning_rate` - Learning rate for training\n",
    "* `keep_prob` - The dropout keep probability when training\n",
    "\n",
    "Andrej Karpathy's advice on [training](https://github.com/karpathy/char-rnn#tips-and-tricks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100        # Sequences per batch\n",
    "num_steps = 100         # Number of sequence steps per batch\n",
    "lstm_size = 512         # Size of hidden layers in LSTMs\n",
    "num_layers = 2          # Number of LSTM layers\n",
    "learning_rate = 0.001   # Learning rate\n",
    "keep_prob = 0.5         # Dropout keep probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Passing inputs and targets into the network, then running the optimizer. Here we also get back the final LSTM state for the mini-batch. Then, we pass that state back into the network so the next batch can continue the state from the previous batch. We also save some checkpoints every n iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20...  Training Step: 50...  Training loss: 3.0730...  0.4601 sec/batch\n",
      "Epoch: 1/20...  Training Step: 100...  Training loss: 2.9392...  0.4634 sec/batch\n",
      "Epoch: 1/20...  Training Step: 150...  Training loss: 2.7657...  0.4595 sec/batch\n",
      "Epoch: 1/20...  Training Step: 200...  Training loss: 2.4986...  0.4603 sec/batch\n",
      "Epoch: 1/20...  Training Step: 250...  Training loss: 2.2682...  0.4621 sec/batch\n",
      "Epoch: 1/20...  Training Step: 300...  Training loss: 2.2063...  0.4618 sec/batch\n",
      "Epoch: 2/20...  Training Step: 350...  Training loss: 2.1164...  0.4598 sec/batch\n",
      "Epoch: 2/20...  Training Step: 400...  Training loss: 2.0545...  0.4614 sec/batch\n",
      "Epoch: 2/20...  Training Step: 450...  Training loss: 2.0349...  0.4609 sec/batch\n",
      "Epoch: 2/20...  Training Step: 500...  Training loss: 1.9373...  0.4620 sec/batch\n",
      "Epoch: 2/20...  Training Step: 550...  Training loss: 1.8834...  0.4621 sec/batch\n",
      "Epoch: 2/20...  Training Step: 600...  Training loss: 1.8656...  0.4621 sec/batch\n",
      "Epoch: 2/20...  Training Step: 650...  Training loss: 1.8214...  0.4616 sec/batch\n",
      "Epoch: 3/20...  Training Step: 700...  Training loss: 1.7904...  0.4604 sec/batch\n",
      "Epoch: 3/20...  Training Step: 750...  Training loss: 1.7601...  0.4605 sec/batch\n",
      "Epoch: 3/20...  Training Step: 800...  Training loss: 1.7079...  0.4608 sec/batch\n",
      "Epoch: 3/20...  Training Step: 850...  Training loss: 1.6705...  0.4614 sec/batch\n",
      "Epoch: 3/20...  Training Step: 900...  Training loss: 1.6683...  0.4613 sec/batch\n",
      "Epoch: 3/20...  Training Step: 950...  Training loss: 1.6306...  0.4600 sec/batch\n",
      "Epoch: 3/20...  Training Step: 1000...  Training loss: 1.5955...  0.4604 sec/batch\n",
      "Epoch: 4/20...  Training Step: 1050...  Training loss: 1.5911...  0.4619 sec/batch\n",
      "Epoch: 4/20...  Training Step: 1100...  Training loss: 1.5621...  0.4613 sec/batch\n",
      "Epoch: 4/20...  Training Step: 1150...  Training loss: 1.5564...  0.4619 sec/batch\n",
      "Epoch: 4/20...  Training Step: 1200...  Training loss: 1.5481...  0.4582 sec/batch\n",
      "Epoch: 4/20...  Training Step: 1250...  Training loss: 1.5202...  0.4606 sec/batch\n",
      "Epoch: 4/20...  Training Step: 1300...  Training loss: 1.4916...  0.4598 sec/batch\n",
      "Epoch: 4/20...  Training Step: 1350...  Training loss: 1.4658...  0.4607 sec/batch\n",
      "Epoch: 5/20...  Training Step: 1400...  Training loss: 1.4478...  0.4581 sec/batch\n",
      "Epoch: 5/20...  Training Step: 1450...  Training loss: 1.4542...  0.4606 sec/batch\n",
      "Epoch: 5/20...  Training Step: 1500...  Training loss: 1.4689...  0.4611 sec/batch\n",
      "Epoch: 5/20...  Training Step: 1550...  Training loss: 1.4342...  0.4601 sec/batch\n",
      "Epoch: 5/20...  Training Step: 1600...  Training loss: 1.4043...  0.4610 sec/batch\n",
      "Epoch: 5/20...  Training Step: 1650...  Training loss: 1.3797...  0.4601 sec/batch\n",
      "Epoch: 6/20...  Training Step: 1700...  Training loss: 1.3798...  0.4611 sec/batch\n",
      "Epoch: 6/20...  Training Step: 1750...  Training loss: 1.4053...  0.4617 sec/batch\n",
      "Epoch: 6/20...  Training Step: 1800...  Training loss: 1.3657...  0.4602 sec/batch\n",
      "Epoch: 6/20...  Training Step: 1850...  Training loss: 1.3762...  0.4626 sec/batch\n",
      "Epoch: 6/20...  Training Step: 1900...  Training loss: 1.3577...  0.4612 sec/batch\n",
      "Epoch: 6/20...  Training Step: 1950...  Training loss: 1.3036...  0.4605 sec/batch\n",
      "Epoch: 6/20...  Training Step: 2000...  Training loss: 1.3196...  0.4601 sec/batch\n",
      "Epoch: 7/20...  Training Step: 2050...  Training loss: 1.3437...  0.4593 sec/batch\n",
      "Epoch: 7/20...  Training Step: 2100...  Training loss: 1.3187...  0.4624 sec/batch\n",
      "Epoch: 7/20...  Training Step: 2150...  Training loss: 1.3055...  0.4614 sec/batch\n",
      "Epoch: 7/20...  Training Step: 2200...  Training loss: 1.2764...  0.4635 sec/batch\n",
      "Epoch: 7/20...  Training Step: 2250...  Training loss: 1.3149...  0.4629 sec/batch\n",
      "Epoch: 7/20...  Training Step: 2300...  Training loss: 1.2794...  0.4620 sec/batch\n",
      "Epoch: 7/20...  Training Step: 2350...  Training loss: 1.3294...  0.4610 sec/batch\n",
      "Epoch: 8/20...  Training Step: 2400...  Training loss: 1.2640...  0.4596 sec/batch\n",
      "Epoch: 8/20...  Training Step: 2450...  Training loss: 1.2792...  0.4610 sec/batch\n",
      "Epoch: 8/20...  Training Step: 2500...  Training loss: 1.2597...  0.4601 sec/batch\n",
      "Epoch: 8/20...  Training Step: 2550...  Training loss: 1.2184...  0.4626 sec/batch\n",
      "Epoch: 8/20...  Training Step: 2600...  Training loss: 1.2993...  0.4615 sec/batch\n",
      "Epoch: 8/20...  Training Step: 2650...  Training loss: 1.2788...  0.4620 sec/batch\n",
      "Epoch: 8/20...  Training Step: 2700...  Training loss: 1.2595...  0.4602 sec/batch\n",
      "Epoch: 9/20...  Training Step: 2750...  Training loss: 1.2655...  0.4610 sec/batch\n",
      "Epoch: 9/20...  Training Step: 2800...  Training loss: 1.2728...  0.4622 sec/batch\n",
      "Epoch: 9/20...  Training Step: 2850...  Training loss: 1.2397...  0.4611 sec/batch\n",
      "Epoch: 9/20...  Training Step: 2900...  Training loss: 1.2230...  0.4627 sec/batch\n",
      "Epoch: 9/20...  Training Step: 2950...  Training loss: 1.2062...  0.4601 sec/batch\n",
      "Epoch: 9/20...  Training Step: 3000...  Training loss: 1.2361...  0.4627 sec/batch\n",
      "Epoch: 10/20...  Training Step: 3050...  Training loss: 1.2178...  0.4620 sec/batch\n",
      "Epoch: 10/20...  Training Step: 3100...  Training loss: 1.2197...  0.4608 sec/batch\n",
      "Epoch: 10/20...  Training Step: 3150...  Training loss: 1.2398...  0.4605 sec/batch\n",
      "Epoch: 10/20...  Training Step: 3200...  Training loss: 1.2311...  0.4603 sec/batch\n",
      "Epoch: 10/20...  Training Step: 3250...  Training loss: 1.2289...  0.4618 sec/batch\n",
      "Epoch: 10/20...  Training Step: 3300...  Training loss: 1.2044...  0.4612 sec/batch\n",
      "Epoch: 10/20...  Training Step: 3350...  Training loss: 1.2435...  0.4594 sec/batch\n",
      "Epoch: 11/20...  Training Step: 3400...  Training loss: 1.2032...  0.4616 sec/batch\n",
      "Epoch: 11/20...  Training Step: 3450...  Training loss: 1.1886...  0.4605 sec/batch\n",
      "Epoch: 11/20...  Training Step: 3500...  Training loss: 1.2143...  0.4608 sec/batch\n",
      "Epoch: 11/20...  Training Step: 3550...  Training loss: 1.2007...  0.4620 sec/batch\n",
      "Epoch: 11/20...  Training Step: 3600...  Training loss: 1.2105...  0.4624 sec/batch\n",
      "Epoch: 11/20...  Training Step: 3650...  Training loss: 1.1936...  0.4601 sec/batch\n",
      "Epoch: 11/20...  Training Step: 3700...  Training loss: 1.1638...  0.4598 sec/batch\n",
      "Epoch: 12/20...  Training Step: 3750...  Training loss: 1.2037...  0.4609 sec/batch\n",
      "Epoch: 12/20...  Training Step: 3800...  Training loss: 1.1624...  0.4616 sec/batch\n",
      "Epoch: 12/20...  Training Step: 3850...  Training loss: 1.1535...  0.4625 sec/batch\n",
      "Epoch: 12/20...  Training Step: 3900...  Training loss: 1.1685...  0.4615 sec/batch\n",
      "Epoch: 12/20...  Training Step: 3950...  Training loss: 1.2008...  0.4610 sec/batch\n",
      "Epoch: 12/20...  Training Step: 4000...  Training loss: 1.1529...  0.4625 sec/batch\n",
      "Epoch: 12/20...  Training Step: 4050...  Training loss: 1.1496...  0.4606 sec/batch\n",
      "Epoch: 13/20...  Training Step: 4100...  Training loss: 1.1636...  0.4609 sec/batch\n",
      "Epoch: 13/20...  Training Step: 4150...  Training loss: 1.1958...  0.4598 sec/batch\n",
      "Epoch: 13/20...  Training Step: 4200...  Training loss: 1.1310...  0.4615 sec/batch\n",
      "Epoch: 13/20...  Training Step: 4250...  Training loss: 1.1518...  0.4608 sec/batch\n",
      "Epoch: 13/20...  Training Step: 4300...  Training loss: 1.1497...  0.4603 sec/batch\n",
      "Epoch: 13/20...  Training Step: 4350...  Training loss: 1.1996...  0.4618 sec/batch\n",
      "Epoch: 14/20...  Training Step: 4400...  Training loss: 1.1447...  0.4623 sec/batch\n",
      "Epoch: 14/20...  Training Step: 4450...  Training loss: 1.1405...  0.4614 sec/batch\n",
      "Epoch: 14/20...  Training Step: 4500...  Training loss: 1.1586...  0.4632 sec/batch\n",
      "Epoch: 14/20...  Training Step: 4550...  Training loss: 1.1448...  0.4599 sec/batch\n",
      "Epoch: 14/20...  Training Step: 4600...  Training loss: 1.1459...  0.4615 sec/batch\n",
      "Epoch: 14/20...  Training Step: 4650...  Training loss: 1.1410...  0.4607 sec/batch\n",
      "Epoch: 14/20...  Training Step: 4700...  Training loss: 1.1695...  0.4631 sec/batch\n",
      "Epoch: 15/20...  Training Step: 4750...  Training loss: 1.1181...  0.4603 sec/batch\n",
      "Epoch: 15/20...  Training Step: 4800...  Training loss: 1.1313...  0.4609 sec/batch\n",
      "Epoch: 15/20...  Training Step: 4850...  Training loss: 1.1389...  0.4599 sec/batch\n",
      "Epoch: 15/20...  Training Step: 4900...  Training loss: 1.1303...  0.4621 sec/batch\n",
      "Epoch: 15/20...  Training Step: 4950...  Training loss: 1.1340...  0.4604 sec/batch\n",
      "Epoch: 15/20...  Training Step: 5000...  Training loss: 1.1083...  0.4618 sec/batch\n",
      "Epoch: 15/20...  Training Step: 5050...  Training loss: 1.1210...  0.4612 sec/batch\n",
      "Epoch: 16/20...  Training Step: 5100...  Training loss: 1.1189...  0.4619 sec/batch\n",
      "Epoch: 16/20...  Training Step: 5150...  Training loss: 1.1296...  0.4619 sec/batch\n",
      "Epoch: 16/20...  Training Step: 5200...  Training loss: 1.0998...  0.4602 sec/batch\n",
      "Epoch: 16/20...  Training Step: 5250...  Training loss: 1.1076...  0.4601 sec/batch\n",
      "Epoch: 16/20...  Training Step: 5300...  Training loss: 1.1575...  0.4602 sec/batch\n",
      "Epoch: 16/20...  Training Step: 5350...  Training loss: 1.0794...  0.4606 sec/batch\n",
      "Epoch: 16/20...  Training Step: 5400...  Training loss: 1.1102...  0.4626 sec/batch\n",
      "Epoch: 17/20...  Training Step: 5450...  Training loss: 1.0947...  0.4620 sec/batch\n",
      "Epoch: 17/20...  Training Step: 5500...  Training loss: 1.1400...  0.4628 sec/batch\n",
      "Epoch: 17/20...  Training Step: 5550...  Training loss: 1.0922...  0.4608 sec/batch\n",
      "Epoch: 17/20...  Training Step: 5600...  Training loss: 1.1382...  0.4619 sec/batch\n",
      "Epoch: 17/20...  Training Step: 5650...  Training loss: 1.1184...  0.4623 sec/batch\n",
      "Epoch: 17/20...  Training Step: 5700...  Training loss: 1.1116...  0.4602 sec/batch\n",
      "Epoch: 18/20...  Training Step: 5750...  Training loss: 1.1043...  0.4615 sec/batch\n",
      "Epoch: 18/20...  Training Step: 5800...  Training loss: 1.1009...  0.4612 sec/batch\n",
      "Epoch: 18/20...  Training Step: 5850...  Training loss: 1.0960...  0.4618 sec/batch\n",
      "Epoch: 18/20...  Training Step: 5900...  Training loss: 1.1190...  0.4601 sec/batch\n",
      "Epoch: 18/20...  Training Step: 5950...  Training loss: 1.1176...  0.4620 sec/batch\n",
      "Epoch: 18/20...  Training Step: 6000...  Training loss: 1.1015...  0.4628 sec/batch\n",
      "Epoch: 18/20...  Training Step: 6050...  Training loss: 1.0870...  0.4615 sec/batch\n",
      "Epoch: 19/20...  Training Step: 6100...  Training loss: 1.1029...  0.4632 sec/batch\n",
      "Epoch: 19/20...  Training Step: 6150...  Training loss: 1.0893...  0.4616 sec/batch\n",
      "Epoch: 19/20...  Training Step: 6200...  Training loss: 1.0922...  0.4619 sec/batch\n",
      "Epoch: 19/20...  Training Step: 6250...  Training loss: 1.0918...  0.4615 sec/batch\n",
      "Epoch: 19/20...  Training Step: 6300...  Training loss: 1.0979...  0.4611 sec/batch\n",
      "Epoch: 19/20...  Training Step: 6350...  Training loss: 1.1043...  0.4615 sec/batch\n",
      "Epoch: 19/20...  Training Step: 6400...  Training loss: 1.1139...  0.4603 sec/batch\n",
      "Epoch: 20/20...  Training Step: 6450...  Training loss: 1.0995...  0.4604 sec/batch\n",
      "Epoch: 20/20...  Training Step: 6500...  Training loss: 1.1024...  0.4600 sec/batch\n",
      "Epoch: 20/20...  Training Step: 6550...  Training loss: 1.0973...  0.4619 sec/batch\n",
      "Epoch: 20/20...  Training Step: 6600...  Training loss: 1.1189...  0.4602 sec/batch\n",
      "Epoch: 20/20...  Training Step: 6650...  Training loss: 1.0805...  0.4617 sec/batch\n",
      "Epoch: 20/20...  Training Step: 6700...  Training loss: 1.0825...  0.4600 sec/batch\n",
      "Epoch: 20/20...  Training Step: 6750...  Training loss: 1.1051...  0.4612 sec/batch\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "# Print losses every N interations\n",
    "print_every_n = 50\n",
    "\n",
    "# Save every N iterations\n",
    "save_every_n = 200\n",
    "\n",
    "model = CharRNN(len(vocab), batch_size=batch_size, num_steps=num_steps,\n",
    "                lstm_size=lstm_size, num_layers=num_layers, \n",
    "                learning_rate=learning_rate)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Use the line below to load a checkpoint and resume training\n",
    "    #saver.restore(sess, 'checkpoints/______.ckpt')\n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        # Train network\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for x, y in get_batches(encoded, batch_size, num_steps):\n",
    "            counter += 1\n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: keep_prob,\n",
    "                    model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.loss, \n",
    "                                                 model.final_state, \n",
    "                                                 model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "            if (counter % print_every_n == 0):\n",
    "                end = time.time()\n",
    "                print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                      'Training Step: {}... '.format(counter),\n",
    "                      'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                      '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))\n",
    "    \n",
    "    saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the saved checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_checkpoint_path: \"checkpoints/i6760_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i200_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i400_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i600_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i800_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i1000_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i1200_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i1400_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i1600_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i1800_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i2000_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i2200_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i2400_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i2600_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i2800_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i3000_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i3200_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i3400_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i3600_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i3800_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i4000_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i4200_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i4400_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i4600_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i4800_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i5000_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i5200_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i5400_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i5600_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i5800_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i6000_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i6200_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i6400_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i6600_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i6760_l512.ckpt\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "\n",
    "We'll use the trained-up network to generate new text. The idea is that we pass in a character, then the network will predict the next character. We can use the new one, to predict the next one. And we keep doing this to generate all new text. To reduce noise and make things a little less random, only choose a new character from the top N most likely characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(checkpoint, n_samples, lstm_size, vocab_size, prime=\"The \"):\n",
    "    samples = [c for c in prime]\n",
    "    model = CharRNN(len(vocab), lstm_size=lstm_size, sampling=True)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for c in prime:\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0,0] = vocab_to_int[c]\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "        c = pick_top_n(preds, len(vocab))\n",
    "        samples.append(int_to_vocab[c])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            x[0,0] = c\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "            c = pick_top_n(preds, len(vocab))\n",
    "            samples.append(int_to_vocab[c])\n",
    "        \n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass in the path to a checkpoint and sample from the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/i6760_l512.ckpt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/i6760_l512.ckpt\n",
      "Farlan,\" he cried. \"It's an\n",
      "     information that he has set one of these, and the conclusions that\n",
      "     I had no doubt. I have not brought at the stript all where he\n",
      "     were that it was not to start in and should show her to--within a\n",
      "     station which has been sent in that dark boy, who had suspicions\n",
      "     which has been a seroratie, and there he was of his house. I would\n",
      "     have a confluence of money as to the side of the maid that, went in\n",
      "     the house of an instructive. He is a state, with a cabbin of\n",
      "     spreadful man, was the matter of any chorting silence. It was too dark\n",
      "     to see it, and then to me, and I could not see him to think.\n",
      "\n",
      "     \"I think we have a clinned to him as if you can discover, I wished to\n",
      "     still think what the case were a secret was from the trouser of his father\n",
      "     and his hand with as were sure at the sight of the singular sorn of\n",
      "     the torthest streamed of her which were alone who were at the\n",
      "     chair. We came to a short bridge. Indeed, as I had taken the single\n",
      "     lodge to the station when we came to make his house and that I came\n",
      "     to ask to make a careffle of the safe in the deach of the\n",
      "     chain of his fortune. In a state of triflacal shadow and the friend\n",
      "     or some direction is wasted in a man who was a painful track of the\n",
      "     dress of the track. Then there was one morting, so that he was to\n",
      "     complete the cab. We had secured that the more surmound that I was\n",
      "     to be the confession of their station. It is to bring him, though I\n",
      "     am sure that I hope that you are the official of the parts of\n",
      "     creature than I am that to have the man, there is no same and\n",
      "     pair, and I am thinking that you have to desire to myself to do it it,\n",
      "     and you are thinking about the precent power of all that I have\n",
      "     to say.\"\n",
      "\n",
      "     \"Ah, it would bring the morning with this methods of and that I was\n",
      "     that it is surely the point which I am sure as you wan that he\n",
      "     has seen the change of my companion'\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "samp = sample(checkpoint, 2000, lstm_size, len(vocab), prime=\"Far\")\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/i200_l512.ckpt\n",
      "Fareserad tothit oee ote tir hire hhae  oot ate hed hretat thar teon.  aod  in ot ee aon. I waed ha  oe ane tine\n",
      "     whe at aon tot in atee\n",
      "     andthe the eth es ortas tin thhe  ised hes aot he thar end oote ao  hhe\n",
      "     an she eretha  ee os et eo tooe  an hee on ter ar hhe  an e ae  on than eso an toee oo ee oter too hhe son hte he te ot ae e ot tin  hoe  oo  aot hot he on hae too e e oe ortee os oe hhre\n",
      "     oe san ee astas taod the e hand ane the an oe tho e ondton ha soet hit tit tit ot ot oor the\n",
      "     at at or hee\n",
      " \n",
      "     I ansd ane hon  ho on et an on ao e ao he ton he tot an the eest an  tertas et han sos toe  ateth hes an thord tees ser ersote hos tere on at too he os erte hes ote toe eroret hh e and areded ho  tee teo teot ho eed osree thoe\n",
      "     teot an he ero ot ot hae\n",
      "     hae tae  ther ton ot ir he one.  on oe hin hat ao too  hh ead tat tat e ot oe  the e as oot oo tee at hed tat har ae or on an tit e ot he eoth e oned on ooe\n",
      "     thee ort har the thee s oot ho  ao ne hoe ane \n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'checkpoints/i200_l512.ckpt'\n",
    "samp = sample(checkpoint, 1000, lstm_size, len(vocab), prime=\"Far\")\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/i600_l512.ckpt\n",
      "Farryould of\n",
      "     heverent to sally has bould, were, as waress toly out of out to\n",
      "     as is a merasion the marke on the remat\n",
      "     wolled to to to then\n",
      "     which, sain I see the tild trees at ance to\n",
      "     with a mearise wercer.\n",
      "\n",
      "\n",
      "     \"The sarks,\"\n",
      "    aris.\"\n",
      "\n",
      "     \"In's thet the sole of the meare, have her hind of throm.\"\n",
      "\n",
      "     \"I have the moren. Ho dess it is anly and at to the\n",
      "     a colm at on the markent of the rows or\n",
      "     cone of a carling the\n",
      "     at a mas hind trased tho dight, was and the lear\n",
      "     seress it ande to so the cas into his, wiste\n",
      "     hese and wat and has hourder.\n",
      "\n",
      "     \"This selo have there wat ta ser at and the\n",
      "     some had the soull. There hive to sert here sarling to\n",
      "     the\n",
      "     shan hored.\"\n",
      "\n",
      "     \"Yes, watery.\"\n",
      "\n",
      "     \"I was hid in andedse that has and here ofer\n",
      "     sere and the courser, his whan I cand it tiss\n",
      "     thit thas in.\n",
      "\n",
      "     \"There wost on the same our he sar he has there of a time\n",
      "     the some.\n",
      "\n",
      "     \"It in shence that I sencole the\n",
      "     homes a\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'checkpoints/i600_l512.ckpt'\n",
    "samp = sample(checkpoint, 1000, lstm_size, len(vocab), prime=\"Far\")\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/i1200_l512.ckpt\n",
      "Farrancy;\n",
      "      a fout of the matter. That his care.\n",
      "\n",
      "     \"I am no saight all some him. How, you an insent that I sam at the\n",
      "     solise of that there of the croubses. We comes at his concinally\n",
      "     stopet and wat they hooke and the betther the poce of this\n",
      "     complain to be when the propinite off once this trach were a stree\n",
      "\n",
      "     and seep to the morres of his stires. I with him. I have not his bright\n",
      "     of the pluan and store thing. Thenes the serven and any sen in hore and\n",
      "     the stare, which was surget a latel and him would be a more wasting it\n",
      "     the soot,\" seid he. I was a pringioned, ard he were this mential\n",
      "     sure of the man when he seored him all whon he had the past, but I\n",
      "     sheally be it is, and as I surd to be a most of the pack, with a\n",
      "     plase was the stare. How have station the mark in the ment of the san\n",
      "     singer.\"\n",
      "\n",
      "     \"Thit he have the sirning--an the poor of a singular, then in that\n",
      "     any the second and have been at hows, what that whine to be in\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'checkpoints/i1200_l512.ckpt'\n",
    "samp = sample(checkpoint, 1000, lstm_size, len(vocab), prime=\"Far\")\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the network - add an embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an embedding layer allows the model to learn a distributed representation of the characters, which can help improve its ability to generalize to new sequences of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(input_data, vocab_size, embedding_size):\n",
    "    \"\"\"\n",
    "    Create embedding for <input_data>.\n",
    "    :param input_data: TF placeholder for text input.\n",
    "    :param vocab_size: Number of words in vocabulary.\n",
    "    :param embedding_size: Number of embedding dimensions\n",
    "    :return: Embedded input.\n",
    "    \"\"\"\n",
    "    embedding = tf.Variable(tf.random_uniform([len(vocab), embedding_size], -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, input_data)\n",
    "    \n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inputs_with_embed(batch_size, num_steps, embedding_size):\n",
    "    ''' Define placeholders for inputs, targets, and dropout \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size: Batch size, number of sequences per batch\n",
    "        num_steps: Number of sequence steps in a batch\n",
    "        embedding_size: Dimensionality of the embedding vector\n",
    "        \n",
    "    '''\n",
    "    # Declare placeholders we'll feed into the graph\n",
    "    inputs = tf.placeholder(tf.int32, [batch_size, num_steps], name='inputs')\n",
    "    targets = tf.placeholder(tf.int32, [batch_size, num_steps], name='targets')\n",
    "    \n",
    "    # Define embedding layer\n",
    "    embed = get_embed(inputs, len(vocab), embedding_size)\n",
    "    \n",
    "    # Keep probability placeholder for drop out layers\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return inputs, targets, embed, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN_modified:\n",
    "    \n",
    "    def __init__(self, num_classes, batch_size=64, num_steps=50, \n",
    "                       lstm_size=128, num_layers=2, learning_rate=0.001, \n",
    "                       grad_clip=5, embedding_size=128, sampling=False):\n",
    "    \n",
    "        if sampling == True:\n",
    "            batch_size, num_steps = 1, 1\n",
    "        else:\n",
    "            batch_size, num_steps = batch_size, num_steps\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Build the input placeholder tensors\n",
    "        self.inputs, self.targets, self.embed, self.keep_prob = build_inputs_with_embed(batch_size, num_steps, embedding_size)\n",
    "\n",
    "        # Build the LSTM cell\n",
    "        cell, self.initial_state = build_lstm(lstm_size, num_layers, batch_size, self.keep_prob)\n",
    "\n",
    "        ### Run the data through the RNN layers\n",
    "        # Run each sequence step through the embedding layer\n",
    "        x = self.embed\n",
    "        \n",
    "        # Run each sequence step through the RNN and collect the outputs\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell, x, initial_state=self.initial_state)\n",
    "        self.final_state = state\n",
    "        \n",
    "        # Get softmax predictions and logits\n",
    "        self.prediction, self.logits = build_output(outputs, lstm_size, num_classes)\n",
    "        \n",
    "        # Loss and optimizer (with gradient clipping)\n",
    "        self.loss = build_loss(self.logits, self.targets, lstm_size, num_classes)\n",
    "        self.optimizer = build_optimizer(self.loss, learning_rate, grad_clip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20...  Training Step: 50...  Training loss: 2.3888...  0.4892 sec/batch\n",
      "Epoch: 1/20...  Training Step: 100...  Training loss: 1.9972...  0.4861 sec/batch\n",
      "Epoch: 1/20...  Training Step: 150...  Training loss: 1.8225...  0.4906 sec/batch\n",
      "Epoch: 1/20...  Training Step: 200...  Training loss: 1.7021...  0.4872 sec/batch\n",
      "Epoch: 1/20...  Training Step: 250...  Training loss: 1.6357...  0.4898 sec/batch\n",
      "Epoch: 1/20...  Training Step: 300...  Training loss: 1.5928...  0.4893 sec/batch\n",
      "Epoch: 2/20...  Training Step: 350...  Training loss: 1.5419...  0.4906 sec/batch\n",
      "Epoch: 2/20...  Training Step: 400...  Training loss: 1.4862...  0.4889 sec/batch\n",
      "Epoch: 2/20...  Training Step: 450...  Training loss: 1.4750...  0.4907 sec/batch\n",
      "Epoch: 2/20...  Training Step: 500...  Training loss: 1.3771...  0.4895 sec/batch\n",
      "Epoch: 2/20...  Training Step: 550...  Training loss: 1.3709...  0.4912 sec/batch\n",
      "Epoch: 2/20...  Training Step: 600...  Training loss: 1.3867...  0.4869 sec/batch\n",
      "Epoch: 2/20...  Training Step: 650...  Training loss: 1.3541...  0.4899 sec/batch\n",
      "Epoch: 3/20...  Training Step: 700...  Training loss: 1.3293...  0.4881 sec/batch\n",
      "Epoch: 3/20...  Training Step: 750...  Training loss: 1.3361...  0.4923 sec/batch\n",
      "Epoch: 3/20...  Training Step: 800...  Training loss: 1.2952...  0.4889 sec/batch\n",
      "Epoch: 3/20...  Training Step: 850...  Training loss: 1.2848...  0.4891 sec/batch\n",
      "Epoch: 3/20...  Training Step: 900...  Training loss: 1.2999...  0.4849 sec/batch\n",
      "Epoch: 3/20...  Training Step: 950...  Training loss: 1.2659...  0.4903 sec/batch\n",
      "Epoch: 3/20...  Training Step: 1000...  Training loss: 1.2428...  0.4868 sec/batch\n",
      "Epoch: 4/20...  Training Step: 1050...  Training loss: 1.2479...  0.4925 sec/batch\n",
      "Epoch: 4/20...  Training Step: 1100...  Training loss: 1.2251...  0.4857 sec/batch\n",
      "Epoch: 4/20...  Training Step: 1150...  Training loss: 1.2394...  0.4871 sec/batch\n",
      "Epoch: 4/20...  Training Step: 1200...  Training loss: 1.2341...  0.4869 sec/batch\n",
      "Epoch: 4/20...  Training Step: 1250...  Training loss: 1.2036...  0.4908 sec/batch\n",
      "Epoch: 4/20...  Training Step: 1300...  Training loss: 1.1853...  0.4861 sec/batch\n",
      "Epoch: 4/20...  Training Step: 1350...  Training loss: 1.1787...  0.4913 sec/batch\n",
      "Epoch: 5/20...  Training Step: 1400...  Training loss: 1.1813...  0.4876 sec/batch\n",
      "Epoch: 5/20...  Training Step: 1450...  Training loss: 1.2072...  0.4913 sec/batch\n",
      "Epoch: 5/20...  Training Step: 1500...  Training loss: 1.1925...  0.4873 sec/batch\n",
      "Epoch: 5/20...  Training Step: 1550...  Training loss: 1.2072...  0.4896 sec/batch\n",
      "Epoch: 5/20...  Training Step: 1600...  Training loss: 1.1659...  0.4892 sec/batch\n",
      "Epoch: 5/20...  Training Step: 1650...  Training loss: 1.1543...  0.4912 sec/batch\n",
      "Epoch: 6/20...  Training Step: 1700...  Training loss: 1.1559...  0.4866 sec/batch\n",
      "Epoch: 6/20...  Training Step: 1750...  Training loss: 1.1805...  0.4916 sec/batch\n",
      "Epoch: 6/20...  Training Step: 1800...  Training loss: 1.1454...  0.4890 sec/batch\n",
      "Epoch: 6/20...  Training Step: 1850...  Training loss: 1.1576...  0.4901 sec/batch\n",
      "Epoch: 6/20...  Training Step: 1900...  Training loss: 1.1376...  0.4858 sec/batch\n",
      "Epoch: 6/20...  Training Step: 1950...  Training loss: 1.1177...  0.4898 sec/batch\n",
      "Epoch: 6/20...  Training Step: 2000...  Training loss: 1.1232...  0.4880 sec/batch\n",
      "Epoch: 7/20...  Training Step: 2050...  Training loss: 1.1427...  0.4923 sec/batch\n",
      "Epoch: 7/20...  Training Step: 2100...  Training loss: 1.1266...  0.4875 sec/batch\n",
      "Epoch: 7/20...  Training Step: 2150...  Training loss: 1.1205...  0.4897 sec/batch\n",
      "Epoch: 7/20...  Training Step: 2200...  Training loss: 1.1007...  0.4889 sec/batch\n",
      "Epoch: 7/20...  Training Step: 2250...  Training loss: 1.1412...  0.4920 sec/batch\n",
      "Epoch: 7/20...  Training Step: 2300...  Training loss: 1.1179...  0.4876 sec/batch\n",
      "Epoch: 7/20...  Training Step: 2350...  Training loss: 1.1396...  0.4907 sec/batch\n",
      "Epoch: 8/20...  Training Step: 2400...  Training loss: 1.0976...  0.4866 sec/batch\n",
      "Epoch: 8/20...  Training Step: 2450...  Training loss: 1.1285...  0.4894 sec/batch\n",
      "Epoch: 8/20...  Training Step: 2500...  Training loss: 1.1039...  0.4868 sec/batch\n",
      "Epoch: 8/20...  Training Step: 2550...  Training loss: 1.0694...  0.4903 sec/batch\n",
      "Epoch: 8/20...  Training Step: 2600...  Training loss: 1.1174...  0.4877 sec/batch\n",
      "Epoch: 8/20...  Training Step: 2650...  Training loss: 1.1256...  0.4910 sec/batch\n",
      "Epoch: 8/20...  Training Step: 2700...  Training loss: 1.1104...  0.4878 sec/batch\n",
      "Epoch: 9/20...  Training Step: 2750...  Training loss: 1.1069...  0.4897 sec/batch\n",
      "Epoch: 9/20...  Training Step: 2800...  Training loss: 1.1268...  0.4876 sec/batch\n",
      "Epoch: 9/20...  Training Step: 2850...  Training loss: 1.0748...  0.4899 sec/batch\n",
      "Epoch: 9/20...  Training Step: 2900...  Training loss: 1.0834...  0.4884 sec/batch\n",
      "Epoch: 9/20...  Training Step: 2950...  Training loss: 1.0711...  0.4904 sec/batch\n",
      "Epoch: 9/20...  Training Step: 3000...  Training loss: 1.0952...  0.4884 sec/batch\n",
      "Epoch: 10/20...  Training Step: 3050...  Training loss: 1.0757...  0.4908 sec/batch\n",
      "Epoch: 10/20...  Training Step: 3100...  Training loss: 1.0930...  0.4895 sec/batch\n",
      "Epoch: 10/20...  Training Step: 3150...  Training loss: 1.1078...  0.4904 sec/batch\n",
      "Epoch: 10/20...  Training Step: 3200...  Training loss: 1.0949...  0.4894 sec/batch\n",
      "Epoch: 10/20...  Training Step: 3250...  Training loss: 1.0907...  0.4891 sec/batch\n",
      "Epoch: 10/20...  Training Step: 3300...  Training loss: 1.0795...  0.4878 sec/batch\n",
      "Epoch: 10/20...  Training Step: 3350...  Training loss: 1.1098...  0.4917 sec/batch\n",
      "Epoch: 11/20...  Training Step: 3400...  Training loss: 1.0768...  0.4871 sec/batch\n",
      "Epoch: 11/20...  Training Step: 3450...  Training loss: 1.0705...  0.4895 sec/batch\n",
      "Epoch: 11/20...  Training Step: 3500...  Training loss: 1.0940...  0.4886 sec/batch\n",
      "Epoch: 11/20...  Training Step: 3550...  Training loss: 1.0756...  0.4910 sec/batch\n",
      "Epoch: 11/20...  Training Step: 3600...  Training loss: 1.0919...  0.4877 sec/batch\n",
      "Epoch: 11/20...  Training Step: 3650...  Training loss: 1.0824...  0.4943 sec/batch\n",
      "Epoch: 11/20...  Training Step: 3700...  Training loss: 1.0498...  0.4874 sec/batch\n",
      "Epoch: 12/20...  Training Step: 3750...  Training loss: 1.0916...  0.4915 sec/batch\n",
      "Epoch: 12/20...  Training Step: 3800...  Training loss: 1.0509...  0.4882 sec/batch\n",
      "Epoch: 12/20...  Training Step: 3850...  Training loss: 1.0383...  0.4919 sec/batch\n",
      "Epoch: 12/20...  Training Step: 3900...  Training loss: 1.0488...  0.4894 sec/batch\n",
      "Epoch: 12/20...  Training Step: 3950...  Training loss: 1.0827...  0.4901 sec/batch\n",
      "Epoch: 12/20...  Training Step: 4000...  Training loss: 1.0315...  0.4881 sec/batch\n",
      "Epoch: 12/20...  Training Step: 4050...  Training loss: 1.0319...  0.4915 sec/batch\n",
      "Epoch: 13/20...  Training Step: 4100...  Training loss: 1.0516...  0.4887 sec/batch\n",
      "Epoch: 13/20...  Training Step: 4150...  Training loss: 1.0887...  0.4917 sec/batch\n",
      "Epoch: 13/20...  Training Step: 4200...  Training loss: 1.0420...  0.4884 sec/batch\n",
      "Epoch: 13/20...  Training Step: 4250...  Training loss: 1.0548...  0.4898 sec/batch\n",
      "Epoch: 13/20...  Training Step: 4300...  Training loss: 1.0400...  0.4879 sec/batch\n",
      "Epoch: 13/20...  Training Step: 4350...  Training loss: 1.0743...  0.4902 sec/batch\n",
      "Epoch: 14/20...  Training Step: 4400...  Training loss: 1.0394...  0.4888 sec/batch\n",
      "Epoch: 14/20...  Training Step: 4450...  Training loss: 1.0418...  0.4912 sec/batch\n",
      "Epoch: 14/20...  Training Step: 4500...  Training loss: 1.0581...  0.4874 sec/batch\n",
      "Epoch: 14/20...  Training Step: 4550...  Training loss: 1.0436...  0.4903 sec/batch\n",
      "Epoch: 14/20...  Training Step: 4600...  Training loss: 1.0451...  0.4877 sec/batch\n",
      "Epoch: 14/20...  Training Step: 4650...  Training loss: 1.0385...  0.4905 sec/batch\n",
      "Epoch: 14/20...  Training Step: 4700...  Training loss: 1.0625...  0.4888 sec/batch\n",
      "Epoch: 15/20...  Training Step: 4750...  Training loss: 1.0207...  0.4918 sec/batch\n",
      "Epoch: 15/20...  Training Step: 4800...  Training loss: 1.0382...  0.4880 sec/batch\n",
      "Epoch: 15/20...  Training Step: 4850...  Training loss: 1.0462...  0.4919 sec/batch\n",
      "Epoch: 15/20...  Training Step: 4900...  Training loss: 1.0340...  0.4897 sec/batch\n",
      "Epoch: 15/20...  Training Step: 4950...  Training loss: 1.0491...  0.4909 sec/batch\n",
      "Epoch: 15/20...  Training Step: 5000...  Training loss: 1.0274...  0.4879 sec/batch\n",
      "Epoch: 15/20...  Training Step: 5050...  Training loss: 1.0166...  0.4890 sec/batch\n",
      "Epoch: 16/20...  Training Step: 5100...  Training loss: 1.0379...  0.4887 sec/batch\n",
      "Epoch: 16/20...  Training Step: 5150...  Training loss: 1.0299...  0.4897 sec/batch\n",
      "Epoch: 16/20...  Training Step: 5200...  Training loss: 1.0196...  0.4868 sec/batch\n",
      "Epoch: 16/20...  Training Step: 5250...  Training loss: 1.0275...  0.4889 sec/batch\n",
      "Epoch: 16/20...  Training Step: 5300...  Training loss: 1.0583...  0.4899 sec/batch\n",
      "Epoch: 16/20...  Training Step: 5350...  Training loss: 0.9961...  0.4905 sec/batch\n",
      "Epoch: 16/20...  Training Step: 5400...  Training loss: 1.0241...  0.4885 sec/batch\n",
      "Epoch: 17/20...  Training Step: 5450...  Training loss: 1.0194...  0.4918 sec/batch\n",
      "Epoch: 17/20...  Training Step: 5500...  Training loss: 1.0398...  0.4884 sec/batch\n",
      "Epoch: 17/20...  Training Step: 5550...  Training loss: 1.0112...  0.4919 sec/batch\n",
      "Epoch: 17/20...  Training Step: 5600...  Training loss: 1.0427...  0.4885 sec/batch\n",
      "Epoch: 17/20...  Training Step: 5650...  Training loss: 1.0220...  0.4902 sec/batch\n",
      "Epoch: 17/20...  Training Step: 5700...  Training loss: 1.0246...  0.4891 sec/batch\n",
      "Epoch: 18/20...  Training Step: 5750...  Training loss: 1.0248...  0.4903 sec/batch\n",
      "Epoch: 18/20...  Training Step: 5800...  Training loss: 1.0227...  0.4885 sec/batch\n",
      "Epoch: 18/20...  Training Step: 5850...  Training loss: 1.0109...  0.4924 sec/batch\n",
      "Epoch: 18/20...  Training Step: 5900...  Training loss: 1.0325...  0.4862 sec/batch\n",
      "Epoch: 18/20...  Training Step: 5950...  Training loss: 1.0371...  0.4917 sec/batch\n",
      "Epoch: 18/20...  Training Step: 6000...  Training loss: 1.0085...  0.4870 sec/batch\n",
      "Epoch: 18/20...  Training Step: 6050...  Training loss: 0.9990...  0.4904 sec/batch\n",
      "Epoch: 19/20...  Training Step: 6100...  Training loss: 1.0137...  0.4897 sec/batch\n",
      "Epoch: 19/20...  Training Step: 6150...  Training loss: 1.0089...  0.4890 sec/batch\n",
      "Epoch: 19/20...  Training Step: 6200...  Training loss: 1.0120...  0.4895 sec/batch\n",
      "Epoch: 19/20...  Training Step: 6250...  Training loss: 1.0040...  0.4934 sec/batch\n",
      "Epoch: 19/20...  Training Step: 6300...  Training loss: 1.0181...  0.4875 sec/batch\n",
      "Epoch: 19/20...  Training Step: 6350...  Training loss: 1.0203...  0.4893 sec/batch\n",
      "Epoch: 19/20...  Training Step: 6400...  Training loss: 1.0301...  0.4890 sec/batch\n",
      "Epoch: 20/20...  Training Step: 6450...  Training loss: 1.0145...  0.4910 sec/batch\n",
      "Epoch: 20/20...  Training Step: 6500...  Training loss: 1.0142...  0.4873 sec/batch\n",
      "Epoch: 20/20...  Training Step: 6550...  Training loss: 1.0167...  0.4920 sec/batch\n",
      "Epoch: 20/20...  Training Step: 6600...  Training loss: 1.0361...  0.4873 sec/batch\n",
      "Epoch: 20/20...  Training Step: 6650...  Training loss: 1.0008...  0.4921 sec/batch\n",
      "Epoch: 20/20...  Training Step: 6700...  Training loss: 1.0093...  0.4874 sec/batch\n",
      "Epoch: 20/20...  Training Step: 6750...  Training loss: 1.0175...  0.4908 sec/batch\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 256\n",
    "\n",
    "epochs = 20\n",
    "# Print losses every N interations\n",
    "print_every_n = 50\n",
    "\n",
    "# Save every N iterations\n",
    "save_every_n = 200\n",
    "\n",
    "model = CharRNN_modified(len(vocab), batch_size=batch_size, num_steps=num_steps,\n",
    "                lstm_size=lstm_size, num_layers=num_layers, \n",
    "                learning_rate=learning_rate, embedding_size=embedding_size)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Use the line below to load a checkpoint and resume training\n",
    "    #saver.restore(sess, 'checkpoints/______.ckpt')\n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        # Train network\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for x, y in get_batches(encoded, batch_size, num_steps):\n",
    "            counter += 1\n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: keep_prob,\n",
    "                    model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.loss, \n",
    "                                                 model.final_state, \n",
    "                                                 model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "            if (counter % print_every_n == 0):\n",
    "                end = time.time()\n",
    "                print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                      'Training Step: {}... '.format(counter),\n",
    "                      'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                      '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))\n",
    "    \n",
    "    saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/i6760_l512.ckpt'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(checkpoint, n_samples, lstm_size, vocab_size, prime=\"The \"):\n",
    "    samples = [c for c in prime]\n",
    "    model = CharRNN_modified(len(vocab), lstm_size=lstm_size, sampling=True, embedding_size=256)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for c in prime:\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0,0] = vocab_to_int[c]\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "        c = pick_top_n(preds, len(vocab))\n",
    "        samples.append(int_to_vocab[c])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            x[0,0] = c\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "            c = pick_top_n(preds, len(vocab))\n",
    "            samples.append(int_to_vocab[c])\n",
    "        \n",
    "    return ''.join(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/i6760_l512.ckpt\n",
      "Farndame and I\n",
      "     had seen the possession of them, sir. I thought how was it, I was\n",
      "     that I could not have had me thrown outside. I have not the signs of a\n",
      "     child. I can hear that the first time that you have already caused all\n",
      "     the time, and that in the way there is one thing about this. If I\n",
      "     waited they can take the case in the station in the hall and all which\n",
      "     I can speak to-day, and I can gather yourself that I would not trust\n",
      "     me a little that we may still see the criminal.\n",
      "\n",
      "     \"This is the time of such a stare at all,\" he remarked with a\n",
      "     low, prisoner. \"They will be the second side of her at the\n",
      "     sound of the meaning,\" said Holmes. \"I am no possible path as you\n",
      "     are in the police, so that it was one of them to tell me only a\n",
      "     lady's secrecy.\"\n",
      "\n",
      "     \"I have not a case which I had not. When they are in the county to\n",
      "     them all this in this middle--and your professional master is a\n",
      "     stranger, and to her has sooner its strain, and this is that we have to\n",
      "     say that that is too power of truth.\"\n",
      "\n",
      "     \"Well, I shall have your companion's.\"\n",
      "\n",
      "     \"In these two, I will not think that they have now been crashed as\n",
      "     it. I wish to me in my son, they have a sight watch.'\n",
      "\n",
      "     \"'There is another sign of me for all that I shall go out of it.\n",
      "     He was on earth of yourself and I wished you. If you saw that, Mr.\n",
      "     Holmes, I'm asking how he is a strong attack to your wife when I\n",
      "     have already seen him. Was there a man into my hands outside his commission?\"\n",
      "\n",
      "     The lady went a client of a leather cold which he saw his perpotion\n",
      "     which he was the confusion, but the shadow had been three of the satisfaction. \n",
      "     She was as walking, which lay a little foot upon the truth, and the\n",
      "     destructed path was closed by a chair which the face was all and on\n",
      "     the hall, with a clue with her hill and handed him up the hat,\n",
      "     blowing the sender of their convict. He was a looking face--and had taken the\n",
      "     cr\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "samp = sample(checkpoint, 2000, lstm_size, len(vocab), prime=\"Far\")\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/i200_l512.ckpt\n",
      "Fard to that the sard and. The comined who whele he strould how her had had no though a sent which way to\n",
      "     asterding if\n",
      "     tather is.\n",
      "\n",
      "     \"There. I was an this mence as\n",
      "     the can at indore to my a tour had been of this astion to me have at the colman, before where have to the shoust was a trince. This was the coul to me, and there all this sating of\n",
      "     his seet who whay the\n",
      "     the sene what is he.\n",
      "\n",
      "     \"As him tell on to take is.\"\n",
      "\n",
      "    \"Whet as she sal to as a sermar of the whough as she was a serponed of my and any were to me a telpested tation and to my of is in all the with that I shuld have tears there is when he was all the dong, but the some of he searth and, as to\n",
      "    sare a seet, and he shough is this\n",
      "     an all striet, bourding that hat the his stertion an sence as as his had on he with ald, so misting other thene with a lite. He was he as\n",
      "     betring that him\n",
      "     the chare alone. Then they some and has the some as that at the canst. It as\n",
      "     he are then with \n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'checkpoints/i200_l512.ckpt'\n",
    "samp = sample(checkpoint, 1000, lstm_size, len(vocab), prime=\"Far\")\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/i600_l512.ckpt\n",
      "Farrren of his\n",
      "     pulicam into my horse. I've the time of attaced. He his arting of\n",
      "     the matter. As was in his last attation. A corning what, we have\n",
      "     the sort on the sternel of the store with shore that when the\n",
      "     diractic and went to some one was the strench. A man hust to see\n",
      "     the son who wished or his cold shorsed of the door, and three\n",
      "     thrown one in the company of he had been a singrion would\n",
      "     heard it that the sight was her sine with a can of the made,\n",
      "     and there was a morning that. That was the moors of the morning\n",
      "     had the dreak of them. That the did seen and seen that what he\n",
      "     seen the papers were in the said which which take the perpor and and\n",
      "     assorting and held. He was now, said he at the sail that there is\n",
      "     her and side--only was heard and hould the moor, the carrage when\n",
      "     I shall be some treet. I am this her thought in the most had heard a\n",
      "     pearous way thrught the path to the place and hurding him. A little\n",
      "     side which\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'checkpoints/i600_l512.ckpt'\n",
    "samp = sample(checkpoint, 1000, lstm_size, len(vocab), prime=\"Far\")\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/i1200_l512.ckpt\n",
      "Farryer.\n",
      "\n",
      "     \"It is this price that if you have say as you will be.\"\n",
      "\n",
      "     \"Well, then?\" He comes. \"It would have how that you ask to any\n",
      "     sound. I am since here there are not interesting to be disappied,\n",
      "     we have no security what we have a man who should be all that you\n",
      "     were that?\"\n",
      "\n",
      "     \"I have been comes what I have alragade all anything whose impression was\n",
      "     already asked at the person in my head too, and his body arred\n",
      "     to-thir one of the compression of the problem and took the passage and his\n",
      "     hand, when there was the conclearently so to the matter. How could\n",
      "     they had thought in the crime, but he was starting to bar me to\n",
      "     any minutes of marriage of the persencion to this shoulder. The\n",
      "     stretches were the case and the silence, and the silent was stole\n",
      "     in his present.\"\n",
      "\n",
      "     \"At the man?\"\n",
      "\n",
      "     \"And you say where were shilled,\" said the short and had threw\n",
      "     the cording face in a straight whom a would be a serven of the stood\n",
      "     and su\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'checkpoints/i1200_l512.ckpt'\n",
    "samp = sample(checkpoint, 1000, lstm_size, len(vocab), prime=\"Far\")\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
